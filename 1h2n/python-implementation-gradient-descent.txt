import numpy as np

#this example is for ( 1 Input – 1 Output )
#Forward Pass
def sigmoid(sop):
    #SOP that's mean Sum Of Products
    return 1/(1+np.exp(-sop))

def error(predected,target):
    return np.power(predected-target,2)

#Backward Pass
def error_prediction_diretive(predict,target):
    return 2*(predict - target)

def activation_sop_derivative(sop):
    return sigmoid(sop) * (1 - sigmoid(sop))

def sop_w_deriv(x):
    return x

def update_w(w,grad,learning_rate):
    return w - learning_rate * grad
#input x
x = 0.1
target = 0.3
learning_rate = 0.001
"""
The weight is initialized randomly using numpy.random.rand()
which returns a number between 0 and 1
"""
w = np.random.rand()
print("Initial Weight: ", w)

# Forward Pass
y = w * x
print("y=",y)
predicted = sigmoid(y)
err = error(predicted, target)
print("error= ",err)


# Backward Pass
"""
the error is calculated using 2 terms which are:
    predicted
    target
"""
g1 = error_prediction_diretive(predicted, target)
print('g1 = ',g1)
g2 = activation_sop_derivative(predicted)
print('g2 = ',g2)
g3 = sop_w_deriv(x)
print('g3 = ',g3)
#This returns the gradient by which the weight value could be updated
"""
Derror/Dw = (Derror/Dpredict)*(Dpredict/Dsop)*(Dsop/Dw)
"""
grad = g3 * g2 * g1
print('grad = ',grad)
print("predicted=",predicted)

second_w = update_w(w, grad, learning_rate)
print("the weight of the input is-->",second_w)

#this is just test
def virefication():
    if round(second_w,4) == round(w,4):
        return print(True)
    else:
        return print(False)

virefication()

